{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d80db16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date     Region                    Product      Unit    Price\n",
      "0     2017-06-01        GBA                Pan francés        kg    38.64\n",
      "1     2017-06-01        GBA      Harina de trigo común        kg    10.67\n",
      "2     2017-06-01        GBA        Arroz blanco simple        kg    20.96\n",
      "3     2017-06-01        GBA  Fideos secos tipo guisero     500 g    19.08\n",
      "4     2017-06-01        GBA         Carne picada común        kg    72.20\n",
      "...          ...        ...                        ...       ...      ...\n",
      "7549  2024-11-01  Patagonia                       Papa        kg  1865.48\n",
      "7550  2024-11-01  Patagonia                     Azúcar        kg  1304.08\n",
      "7551  2024-11-01  Patagonia         Detergente líquido    750 cc  2828.10\n",
      "7552  2024-11-01  Patagonia                  Lavandina  1.000 cc  1228.51\n",
      "7553  2024-11-01  Patagonia           Jabón de tocador     125 g  1011.40\n",
      "\n",
      "[7554 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "import re\n",
    "\n",
    "def find_and_return_xls_link(page_url, reference_text=None):\n",
    "    \"\"\"\n",
    "    Finds and returns the most relevant .xls file link from a webpage.\n",
    "\n",
    "    Parameters:\n",
    "        page_url (str): URL of the webpage to scrape for .xls links.\n",
    "        reference_text (str, optional): A keyword or phrase to prioritize a specific link.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The URL of the .xls file if found, otherwise None.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36\"\n",
    "    }\n",
    "    session = requests.Session()\n",
    "    try:\n",
    "        # Send a GET request to the webpage\n",
    "        response = session.get(page_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Find all anchor tags with .xls links\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "        xls_links = [link for link in links if link[\"href\"].endswith(\".xls\")]\n",
    "        \n",
    "        # Return None if no links are found\n",
    "        if not xls_links:\n",
    "            return None\n",
    "        \n",
    "        # Prioritize links containing the reference text if provided\n",
    "        if reference_text:\n",
    "            for link in xls_links:\n",
    "                if reference_text.lower() in link.text.lower():\n",
    "                    result = link[\"href\"]\n",
    "                    break\n",
    "            else:\n",
    "                result = xls_links[-1][\"href\"]  # Default to the last link\n",
    "        else:\n",
    "            result = xls_links[-1][\"href\"]\n",
    "            \n",
    "        # Ensure the link is an absolute URL\n",
    "        if not result.startswith(\"http\"):\n",
    "            base_url = \"/\".join(page_url.split(\"/\")[:3])\n",
    "            result = base_url + result\n",
    "\n",
    "        return result\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        #print(f\"Error accessing the website: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_valid_excel(content):\n",
    "    \"\"\"\n",
    "    Validates whether the given content is a valid Excel file.\n",
    "\n",
    "    Parameters:\n",
    "        content (bytes): Binary content of the file to validate.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the content is a valid Excel file, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with BytesIO(content) as data:\n",
    "            pd.ExcelFile(data) # Attempt to open the file as an Excel file\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_excel(url):\n",
    "    \"\"\"\n",
    "    Downloads an Excel file from a given URL.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): URL of the file to download.\n",
    "\n",
    "    Returns:\n",
    "        bytes or None: Binary content of the file if successfully downloaded, otherwise None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        #print(f\"Error downloading file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_empty_dataframe():\n",
    "    \"\"\"\n",
    "    Creates an empty DataFrame with predefined column names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: An empty DataFrame with columns for date, region, product, unit, and price.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(columns=[\"Date\", \"Region\", \"Product\", \"Unit\", \"Price\"])\n",
    "\n",
    "\n",
    "def find_sheet(file_content, sheet_name):\n",
    "    \"\"\"\n",
    "    Finds a sheet in an Excel file by name, case-insensitively.\n",
    "\n",
    "    Parameters:\n",
    "        file_content (bytes): Binary content of the Excel file.\n",
    "        sheet_name (str): The name of the sheet to find.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the matched sheet, or the first sheet if no match is found.\n",
    "    \"\"\"\n",
    "    with BytesIO(file_content) as file_data:\n",
    "        # Load all sheet names from the Excel file\n",
    "        sheets = pd.ExcelFile(file_data).sheet_names\n",
    "    for sheet in sheets:\n",
    "        if sheet.lower() == sheet_name.lower():\n",
    "            return sheet\n",
    "        \n",
    "    # Default to the first sheet if the desired one is not found\n",
    "    #print(f\"Sheet '{sheet_name}' not found. Using the first available sheet.\")\n",
    "    return sheets[0]\n",
    "\n",
    "\n",
    "def pandas_data(file_content, sheet_name, df):\n",
    "    # Read the specified sheet from the file\n",
    "    with BytesIO(file_content) as file_data:\n",
    "        excel_data = pd.ExcelFile(file_data)\n",
    "        actual_sheet_name = find_sheet(file_content, sheet_name)\n",
    "        sheet_data = pd.read_excel(excel_data, sheet_name=actual_sheet_name, header=None)\n",
    "        \n",
    "    #define all lists\n",
    "    price_data = []\n",
    "    region_data = []\n",
    "    product_data = []\n",
    "    unit_data = []\n",
    "    date_data = []\n",
    "    \n",
    "    # define region list\n",
    "    valid_regions = [\"GBA\", \"Pampeana\", \"Noreste\", \"Noroeste\", \"Cuyo\", \"Patagonia\"]\n",
    "    \n",
    "    # Dictionary to convert months to numeric format\n",
    "    month_mapping = {\n",
    "        \"Enero\": \"01\", \"Febrero\": \"02\", \"Marzo\": \"03\", \"Abril\": \"04\",\n",
    "        \"Mayo\": \"05\", \"Junio\": \"06\", \"Julio\": \"07\", \"Agosto\": \"08\",\n",
    "        \"Septiembre\": \"09\", \"Octubre\": \"10\", \"Noviembre\": \"11\", \"Diciembre\": \"12\"\n",
    "    }\n",
    "    \n",
    "    # Keep the last year found\n",
    "    last_year_found = None\n",
    "    \n",
    "    for col_idx, column_data in sheet_data.items():\n",
    "        for row_idx, value in enumerate(column_data):\n",
    "            #int and float values greater than 0\n",
    "            if isinstance(value, (int, float)) and value > 0: \n",
    "                price_data.append(value)\n",
    "                # Find months and years in the same column\n",
    "                date_found = None\n",
    "                year_found = None\n",
    "                for cell_idx, cell_value in enumerate(column_data):\n",
    "                    if isinstance(cell_value, str):\n",
    "                        if cell_value in month_mapping:\n",
    "                            date_found = month_mapping[cell_value]\n",
    "                        elif re.match(r\"(?i)año \\d{4}\", cell_value):\n",
    "                            year_found = re.search(r\"\\d{4}\", cell_value).group()\n",
    "                            # Actualizar el último año encontrado\n",
    "                            last_year_found = year_found   \n",
    "                        if date_found and year_found:\n",
    "                            break\n",
    "                # Use the last year found if a current one is not found\n",
    "                if date_found and not year_found:\n",
    "                    year_found = last_year_found\n",
    "                    \n",
    "                # Combine year and month if both are found\n",
    "                if date_found and year_found:\n",
    "                    full_date = f\"{year_found}-{date_found}-01\"\n",
    "                else:\n",
    "                    full_date = None\n",
    "                    \n",
    "                # Find regions and products in the same row\n",
    "                row = sheet_data.iloc[row_idx]\n",
    "                region_found = None\n",
    "                product_found = None\n",
    "                for idx, check_value in enumerate(row):\n",
    "                     if isinstance(check_value, str) and check_value in valid_regions:\n",
    "                        region_found = check_value\n",
    "                        \n",
    "                        # Find the immediate str cell after the region for products\n",
    "                        for next_value in row[idx + 1:]:\n",
    "                            if isinstance(next_value, str):\n",
    "                                product_found = next_value\n",
    "                                break\n",
    "                        product_data.append(product_found)\n",
    "                        # Find the immediate str cell after the region for units\n",
    "                        for next_value in row[idx + 2:]:\n",
    "                            if isinstance(next_value, str):\n",
    "                                product_found = next_value\n",
    "                                break\n",
    "                        unit_data.append(product_found) \n",
    "                        break\n",
    "                        \n",
    "                # If a valid region is not found, take the first cells in the row\n",
    "                if not region_found:\n",
    "                    region_found = row.iloc[0] if isinstance(row.iloc[0], str) else None\n",
    "                    #Take the second cell for the product\n",
    "                    product_found = row.iloc[1] if len(row) > 1 and isinstance(row.iloc[1], str) else None\n",
    "                    product_data.append(product_found)\n",
    "                    #Take the third cell for the units\n",
    "                    unit_found = row.iloc[2] if len(row) > 2 and isinstance(row.iloc[2], str) else None\n",
    "                    unit_data.append(product_found)   \n",
    "\n",
    "                date_data.append(full_date)\n",
    "                region_data.append(region_found)\n",
    "                \n",
    "    # Add the data to the columns 'Price', 'Region', 'Product','Unit', and 'Date'\n",
    "    if price_data:\n",
    "        df = df.reindex(range(len(price_data)))\n",
    "        df[\"Price\"] = [round(price, 2) for price in price_data]\n",
    "        df[\"Region\"] = region_data\n",
    "        df[\"Product\"] = product_data\n",
    "        df[\"Unit\"] = unit_data\n",
    "        df[\"Date\"] = date_data\n",
    "\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    file_url = \"https://www.indec.gob.ar/ftp/cuadros/economia/sh_ipc_precios_promedio.xls\"\n",
    "    fallback_url = \"https://www.indec.gob.ar/Nivel4/Tema/3/5/31\"\n",
    "    reference_text = \"Índice de precios al consumidor\"\n",
    "\n",
    "    content = download_excel(file_url)\n",
    "    \n",
    "    # Check if the downloaded file is valid\n",
    "    if content is None or not is_valid_excel(content):\n",
    "        # Search for an alternative dynamic link in the fallback URL\n",
    "        dynamic_url = find_and_return_xls_link(fallback_url, reference_text)\n",
    "        if dynamic_url:\n",
    "            # If a dynamic link is found, attempt to download the file\n",
    "            content = download_excel(dynamic_url)\n",
    "            \n",
    "        else:\n",
    "            # If no alternative link is found, terminate the execution\n",
    "            #print(\"No dynamic link to the file was found.\")\n",
    "            return\n",
    "\n",
    "    if content and is_valid_excel(content):\n",
    "        df = create_empty_dataframe()\n",
    "        df = pandas_data(content, \"Nacional\", df)\n",
    "        print(df)\n",
    "        df.to_csv(\"indec_consumer_price_index.csv\", index=False)\n",
    "    else:\n",
    "        print(\"The downloaded content is not a valid Excel file.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f6dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
